/**
 * Generates an optimized image classification training script that:
 * 1. Uses flow_from_directory for folder-based datasets (like CIFAR-10)
 * 2. Provides verbose real-time logging
 * 3. Saves metrics.json for frontend detection
 * 4. Properly configures GPU for TensorFlow
 */
export function generateOptimizedImageScript(config: {
    taskType: string;
    targetColumn: string;
    algorithm: string;
}): string {
    const { taskType, targetColumn, algorithm } = config;

    return `# AutoML Generated Script
# Algorithm: ${algorithm} (Convolutional Neural Network)
# Task Type: ${taskType}
# Target Column: ${targetColumn}
# Generated by AutoForgeML Studio

import os
import json
import sys
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# GPU Configuration
print("Checking GPU availability...")
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"GPU detected: {len(gpus)} device(s)")
        for i, gpu in enumerate(gpus):
            print(f"   GPU {i}: {gpu.name}")
    except RuntimeError as e:
        print(f"GPU setup error: {e}")
else:
    print("No GPU detected, falling back to CPU (training will be slow)")

# Configuration - Uses environment variables if set, otherwise AI-recommended defaults
IMAGE_SIZE = (128, 128)
BATCH_SIZE = int(os.environ.get('MLFORGE_BATCH_SIZE', 32))  # AI default: 32
EPOCHS = int(os.environ.get('MLFORGE_EPOCHS', 20))  # AI default: 20
LEARNING_RATE = float(os.environ.get('MLFORGE_LEARNING_RATE', 0.001))  # AI default: 0.001
MODEL_OUTPUT_PATH = os.environ.get('MODEL_OUTPUT_PATH', './model_output')

print(f"Training Configuration:")
print(f"  - Epochs: {EPOCHS}")
print(f"  - Batch Size: {BATCH_SIZE}")
print(f"  - Learning Rate: {LEARNING_RATE}")
print(f"  - Image Size: {IMAGE_SIZE}")

# Custom callback for verbose logging
class VerboseLogger(Callback):
    def on_epoch_begin(self, epoch, logs=None):
        print(f"\\n{'='*50}")
        print(f"Epoch {epoch + 1}/{EPOCHS}")
        print(f"{'='*50}")
        sys.stdout.flush()
    
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        print(f"Training   - loss: {logs.get('loss', 0):.4f}, accuracy: {logs.get('accuracy', 0):.4f}")
        print(f"Validation - loss: {logs.get('val_loss', 0):.4f}, accuracy: {logs.get('val_accuracy', 0):.4f}")
        sys.stdout.flush()
    
    def on_batch_end(self, batch, logs=None):
        # Log every 50 batches
        if batch % 50 == 0:
            logs = logs or {}
            print(f"  Batch {batch}: loss={logs.get('loss', 0):.4f}, acc={logs.get('accuracy', 0):.4f}")
            sys.stdout.flush()

def find_dataset_path():
    """Find the dataset path - handles deeply nested folder structures"""
    print("\\n" + "="*50)
    print("DATASET DISCOVERY")
    print("="*50)
    
    # Search paths in order of priority (RunPod uses /workspace/training)
    search_roots = [
        './dataset',                    # Relative to current dir
        '/workspace/training/dataset',  # RunPod absolute path
        './data', 
        '.',
        '/workspace/training',          # Parent dir in RunPod
        '/tmp/dataset',
        '/tmp/training/dataset'
    ]
    
    # Debug: Show which search paths actually exist
    print("Checking search paths:")
    for path in search_roots:
        exists = os.path.exists(path)
        is_dir = os.path.isdir(path) if exists else False
        print(f"  {path}: {'EXISTS' if exists else 'missing'} {'(dir)' if is_dir else ''}")
    
    def get_subdirs(path):
        """Get subdirectories excluding system folders"""
        if not os.path.exists(path):
            return []
        return [d for d in os.listdir(path) 
                if os.path.isdir(os.path.join(path, d)) 
                and d not in ['__pycache__', '.git', 'model_output', '__MACOSX']]
    
    def has_images(folder_path):
        """Check if folder contains image files"""
        try:
            files = os.listdir(folder_path)[:20]
            image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')
            return any(f.lower().endswith(image_extensions) for f in files)
        except:
            return False
    
    def find_train_test_structure(base_path, depth=0, max_depth=4):
        """Recursively find train/test folder structure"""
        if depth > max_depth or not os.path.exists(base_path):
            return None
        
        subdirs = get_subdirs(base_path)
        subdir_lower = {d.lower(): d for d in subdirs}
        
        # Check for train/test split at this level
        train_names = ['train', 'training']
        for train_name in train_names:
            if train_name in subdir_lower:
                train_dir = os.path.join(base_path, subdir_lower[train_name])
                train_subdirs = get_subdirs(train_dir)
                
                # Verify train folder has class subfolders with images
                if len(train_subdirs) > 0:
                    first_class = os.path.join(train_dir, train_subdirs[0])
                    if has_images(first_class):
                        print(f"Found train/test structure at: {base_path}")
                        print(f"  Train folder: {train_dir} ({len(train_subdirs)} classes)")
                        
                        # Look for test/val folder
                        test_dir = None
                        for test_name in ['test', 'val', 'validation', 'valid']:
                            if test_name in subdir_lower:
                                test_dir = os.path.join(base_path, subdir_lower[test_name])
                                print(f"  Test folder: {test_dir}")
                                break
                        
                        return train_dir, test_dir
        
        # Check if current folder has class folders with images (flat structure)
        if len(subdirs) > 1:
            first_class = os.path.join(base_path, subdirs[0])
            if has_images(first_class):
                print(f"Found class-folder structure at: {base_path}")
                print(f"  Classes: {len(subdirs)}")
                return base_path, None
        
        # Recurse into subdirectories
        for subdir in subdirs:
            result = find_train_test_structure(os.path.join(base_path, subdir), depth + 1, max_depth)
            if result:
                return result
        
        return None
    
    # Search each root path
    for root in search_roots:
        print(f"Checking: {root}")
        if os.path.exists(root):
            # List top-level contents for debugging
            contents = get_subdirs(root)
            print(f"  Contents: {contents[:5]}{'...' if len(contents) > 5 else ''}")
            
            result = find_train_test_structure(root)
            if result:
                return result
    
    # Last resort: print directory tree for debugging
    print("\\n" + "="*50)
    print("ERROR: Could not find valid image dataset!")
    print("="*50)
    print(f"Current working directory: {os.getcwd()}")
    print(f"Searched paths: {search_roots}")
    print("\\nDirectory tree from current location:")
    for root in ['.',  './dataset', '/workspace/training']:
        if os.path.exists(root):
            print(f"\\n{root}/")
            for dirpath, dirnames, filenames in os.walk(root):
                depth = dirpath.replace(root, '').count(os.sep)
                if depth < 3:  # Only show 3 levels
                    indent = '  ' * (depth + 1)
                    print(f"{indent}{os.path.basename(dirpath) or root}/ ({len(filenames)} files)")
    
    raise ValueError(f"Could not find valid image dataset. CWD: {os.getcwd()}")

def create_model(num_classes):
    """Create a robust CNN for image classification"""
    print(f"\\nCreating CNN model for {num_classes} classes...")
    
    model = models.Sequential([
        layers.Rescaling(1./255, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
        
        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        
        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),
        
        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),
        
        layers.Flatten(),
        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    print("\\nModel Architecture:")
    model.summary()
    return model

def load_tfrecord_dataset(shards_dir, batch_size=32, image_size=(128, 128)):
    """Load dataset from TFRecord shards - FAST PATH"""
    import json
    
    metadata_path = os.path.join(shards_dir, 'metadata.json')
    with open(metadata_path) as f:
        metadata = json.load(f)
    
    num_classes = metadata['numClasses']
    class_names = metadata['classNames']
    
    # Get shard file paths
    train_shards = [os.path.join(shards_dir, p) for p in metadata['shardPaths']['train']]
    val_shards = [os.path.join(shards_dir, p) for p in metadata['shardPaths'].get('val', [])]
    
    print(f"\\nLoading TFRecord shards:")
    print(f"  Training shards: {len(train_shards)}")
    print(f"  Validation shards: {len(val_shards)}")
    print(f"  Classes: {num_classes}")
    
    def parse_example(serialized):
        features = tf.io.parse_single_example(serialized, {
            'image': tf.io.FixedLenFeature([], tf.string),
            'label': tf.io.FixedLenFeature([], tf.int64),
        })
        
        image = tf.io.decode_image(features['image'], channels=3, expand_animations=False)
        image = tf.image.resize(image, image_size)
        image = tf.cast(image, tf.float32) / 255.0
        
        label = tf.one_hot(tf.cast(features['label'], tf.int32), num_classes)
        return image, label
    
    # Create training dataset
    train_dataset = tf.data.TFRecordDataset(train_shards)
    train_dataset = train_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)
    train_dataset = train_dataset.shuffle(10000)
    train_dataset = train_dataset.batch(batch_size)
    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)
    
    # Create validation dataset
    if val_shards:
        val_dataset = tf.data.TFRecordDataset(val_shards)
        val_dataset = val_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)
        val_dataset = val_dataset.batch(batch_size)
        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)
    else:
        val_dataset = None
    
    return train_dataset, val_dataset, metadata

def main():
    print("="*60)
    print("AutoForgeML Image Classification Training")
    print("="*60)
    
    try:
        # Check for TFRecord shards first (FAST PATH)
        shards_dir = './shards'
        use_tfrecord = os.path.exists(shards_dir) and os.path.exists(os.path.join(shards_dir, 'metadata.json'))
        
        if use_tfrecord:
            print("\\nðŸš€ FAST PATH: Loading from TFRecord shards")
            train_dataset, val_dataset, metadata = load_tfrecord_dataset(shards_dir, BATCH_SIZE, IMAGE_SIZE)
            
            num_classes = metadata['numClasses']
            class_names = metadata['classNames']
            train_samples = metadata['trainSamples']
            val_samples = metadata.get('valSamples', 0)
            
            print(f"\\nDataset Statistics:")
            print(f"  Classes: {num_classes}")
            print(f"  Class names: {class_names[:5]}{'...' if len(class_names) > 5 else ''}")
            print(f"  Training samples: {train_samples}")
            print(f"  Validation samples: {val_samples}")
            
            # Create model and train
            model = create_model(num_classes)
            
            callbacks = [
                VerboseLogger(),
                EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)
            ]
            
            print(f"\\n{'='*60}")
            print(f"Starting training for {EPOCHS} epochs...")
            print(f"{'='*60}")
            
            history = model.fit(
                train_dataset, 
                epochs=EPOCHS, 
                validation_data=val_dataset,
                callbacks=callbacks, 
                verbose=0
            )
            
            # Evaluate
            print(f"\\n{'='*60}")
            print("Final Evaluation")
            print(f"{'='*60}")
            
            val_loss, val_acc = model.evaluate(val_dataset, verbose=0)
            print(f"Validation Accuracy: {val_acc:.4f}")
            print(f"Validation Loss: {val_loss:.4f}")
            
            # Save model and metrics
            print(f"\\nSaving model to {MODEL_OUTPUT_PATH}...")
            os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)
            model.save(os.path.join(MODEL_OUTPUT_PATH, 'model.h5'))
            
            metrics = {
                'accuracy': float(val_acc),
                'loss': float(val_loss),
                'num_classes': num_classes,
                'class_names': class_names,
                'training_samples': train_samples,
                'validation_samples': val_samples,
                'epochs_trained': len(history.history.get('loss', [])),
                'loaded_from': 'tfrecord_shards'
            }
            
            import json
            with open('metrics.json', 'w') as f:
                json.dump(metrics, f, indent=2)
            print("Saved metrics.json")
            
            print(f"\\n{'='*60}")
            print("SUCCESS: Training pipeline completed!")
            print(f"{'='*60}")
            return
        
        # LEGACY PATH: Load from image folders
        print("\\nðŸ“ LEGACY PATH: Loading from image folders")
        train_path, test_path = find_dataset_path()
        print(f"Training data path: {train_path}")
        if test_path:
            print(f"Test data path: {test_path}")
        
        class_names = sorted([d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))])
        num_classes = len(class_names)
        
        total_train = 0
        for c in class_names:
            class_path = os.path.join(train_path, c)
            count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            total_train += count
        
        print(f"\\nDataset Statistics:")
        print(f"  Classes: {num_classes}")
        print(f"  Class names: {class_names[:5]}{'...' if len(class_names) > 5 else ''}")
        print(f"  Total training images: {total_train}")
        
        # CRITICAL VALIDATION: Check we have valid data before proceeding
        if num_classes < 2:
            print(f"\\n{'='*60}")
            print("ERROR: Need at least 2 classes for classification!")
            print(f"{'='*60}")
            print(f"Found only {num_classes} class(es): {class_names}")
            print(f"\\nDirectory structure at {train_path}:")
            for item in os.listdir(train_path)[:10]:
                item_path = os.path.join(train_path, item)
                if os.path.isdir(item_path):
                    files = os.listdir(item_path)[:3]
                    print(f"  ðŸ“ {item}/ ({len(os.listdir(item_path))} files): {files}...")
                else:
                    print(f"  ðŸ“„ {item}")
            raise ValueError(f"Classification requires at least 2 classes, found {num_classes}")
        
        if total_train == 0:
            print(f"\\n{'='*60}")
            print("ERROR: No training images found!")
            print(f"{'='*60}")
            print(f"Searched in: {train_path}")
            print("Looking for: .png, .jpg, .jpeg files in class subfolders")
            raise ValueError("No training images found in dataset")
        
        # Show per-class counts for debugging
        print("\\nPer-class image counts:")
        for c in class_names[:10]:
            class_path = os.path.join(train_path, c)
            count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            print(f"  {c}: {count} images")
        if len(class_names) > 10:
            print(f"  ... and {len(class_names) - 10} more classes")
        
        print(f"\\nCreating data generators (image size: {IMAGE_SIZE})...")
        print(f"NOTE: Images will be rescaled to 0-1 range for training")
        
        if test_path and os.path.exists(test_path):
            # Separate train/test folders - no validation split needed
            train_datagen = ImageDataGenerator(rescale=1./255)
            val_datagen = ImageDataGenerator(rescale=1./255)
            
            train_generator = train_datagen.flow_from_directory(
                train_path, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
                class_mode='categorical', shuffle=True
            )
            val_generator = val_datagen.flow_from_directory(
                test_path, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
                class_mode='categorical', shuffle=False
            )
        else:
            # Single folder - use 20% validation split
            print("No separate test folder found, using 20% validation split...")
            train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
            
            train_generator = train_datagen.flow_from_directory(
                train_path, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
                class_mode='categorical', subset='training', shuffle=True
            )
            val_generator = train_datagen.flow_from_directory(
                train_path, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
                class_mode='categorical', subset='validation', shuffle=False
            )
        
        print(f"Training samples: {train_generator.samples}")
        print(f"Validation samples: {val_generator.samples}")
        
        # CRITICAL: Validate generators actually found images
        if train_generator.samples == 0:
            print(f"\\n{'='*60}")
            print("FATAL ERROR: No training images loaded by generator!")
            print(f"{'='*60}")
            print(f"Path: {train_path}")
            print(f"Image size: {IMAGE_SIZE}")
            print(f"Expected classes: {class_names[:5]}")
            print("\\nPossible causes:")
            print("  1. Image files are corrupted or in unsupported format")
            print("  2. All images were filtered out (wrong extension)")
            print("  3. Class folders are empty or contain only non-image files")
            print("\\nFiles in first class folder:")
            if class_names:
                first_class_path = os.path.join(train_path, class_names[0])
                if os.path.exists(first_class_path):
                    files = os.listdir(first_class_path)[:10]
                    for f in files:
                        print(f"    {f}")
            raise ValueError("ImageDataGenerator found 0 training samples")
        
        if val_generator.samples == 0:
            print("WARNING: No validation samples! Training will continue but no validation metrics.")
        
        model = create_model(num_classes)
        
        callbacks = [
            VerboseLogger(),
            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)
        ]
        
        print(f"\\n{'='*60}")
        print(f"Starting training for {EPOCHS} epochs...")
        print(f"{'='*60}")
        
        history = model.fit(
            train_generator, epochs=EPOCHS, validation_data=val_generator,
            callbacks=callbacks, verbose=0
        )
        
        print(f"\\n{'='*60}")
        print("Final Evaluation")
        print(f"{'='*60}")
        
        val_loss, val_acc = model.evaluate(val_generator, verbose=0)
        print(f"Validation Accuracy: {val_acc:.4f}")
        print(f"Validation Loss: {val_loss:.4f}")
        
        print("\\nGenerating predictions for classification report...")
        y_pred_prob = model.predict(val_generator, verbose=0)
        y_pred = np.argmax(y_pred_prob, axis=1)
        y_true = val_generator.classes
        
        print("\\nClassification Report:")
        class_labels = list(val_generator.class_indices.keys())
        print(classification_report(y_true, y_pred, target_names=class_labels[:20]))
        
        print(f"\\nSaving model to {MODEL_OUTPUT_PATH}...")
        os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)
        model.save(os.path.join(MODEL_OUTPUT_PATH, 'model.h5'))
        
        history_dict = {}
        for key, value in history.history.items():
            history_dict[key] = [float(v) for v in value]
        
        metrics = {
            'accuracy': float(val_acc),
            'loss': float(val_loss),
            'num_classes': num_classes,
            'class_names': class_labels,
            'training_samples': train_generator.samples,
            'validation_samples': val_generator.samples,
            'epochs_trained': len(history.history.get('loss', [])),
            'history': history_dict
        }
        
        with open('metrics.json', 'w') as f:
            json.dump(metrics, f, indent=2)
        print("Saved metrics.json")
        
        with open(os.path.join(MODEL_OUTPUT_PATH, 'metrics.json'), 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"\\n{'='*60}")
        print("SUCCESS: Training pipeline completed!")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"\\nERROR: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == '__main__':
    main()
`;
}
